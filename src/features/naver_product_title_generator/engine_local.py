"""
ë„¤ì´ë²„ ìƒí’ˆëª… ìƒì„±ê¸° ë¡œì»¬ ì—”ì§„
ìˆœìˆ˜ í•¨ìˆ˜ ê¸°ë°˜ í•µì‹¬ ì•Œê³ ë¦¬ì¦˜ (I/O ì—†ìŒ)
"""
from typing import List, Dict, Any, Optional
import re
import math
from collections import Counter

from .models import KeywordBasicData, GeneratedTitle


# AI í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ (ê³µìš© - ëª¨ë“  í”„ë¡¬í”„íŠ¸ì— ìë™ ì¶”ê°€)
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ë„¤ì´ë²„ ì‡¼í•‘ ìƒí’ˆëª… ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.  
ì•„ë˜ ìƒí’ˆëª…ì„ ë¶„ì„í•´, ì‚¬ëŒë“¤ì´ ì‹¤ì œ ê²€ìƒ‰í•  ê°€ëŠ¥ì„±ì´ ë†’ì€ í‚¤ì›Œë“œë¥¼ ëŒ€ëŸ‰ ìƒì„±í•˜ì„¸ìš”.  
ê²°ê³¼ëŠ” ë„¤ì´ë²„ ì›”ê°„ ê²€ìƒ‰ëŸ‰ API ë¹„êµìš©ì´ë©°, ëª¨ë“  ì¹´í…Œê³ ë¦¬ì— ê³µìš©ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.

ğŸ”¸ í•„ìˆ˜ ì¶œë ¥ í˜•ì‹ (ì‚¬ìš©ì ê·œì¹™ê³¼ ìƒê´€ì—†ì´ ë°˜ë“œì‹œ ì¤€ìˆ˜)
- í‚¤ì›Œë“œë§Œ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ í•œ ì¤„ì— ì¶œë ¥
- ì„¤ëª…/ë¨¸ë¦¬ë§/ì½”ë“œë¸”ë¡ ê¸ˆì§€.
- ê° í‚¤ì›Œë“œëŠ” **2~15ì**, **ìµœëŒ€ 3ì–´ì ˆ**, **ë°”ì´ê·¸ë¨/íŠ¸ë¼ì´ê·¸ë¨ì€ ì•µì»¤ í¬í•¨ í•„ìˆ˜**.
- single + bigram + trigram í•©ì‚° 300ê°œ ì´ìƒì˜ í‚¤ì›Œë“œ ìƒì„±
- ì¡°ê±´ ë¯¸ë‹¬ ì‹œ ê°œìˆ˜ í™•ë³´ ìœ„í•´ ê·œì¹™ ì™„í™” ê°€ëŠ¥.

[ìì²´ ì ê²€(ì¶œë ¥ ì§ì „)]
- [ ] ì„ ë‘ ë¸Œëœë“œ/ê´„í˜¸ ë¸”ë¡ ì œê±°ë¨?
- [ ] í”„ë¡œëª¨ì…˜/í¬ì¥/ìˆ˜ëŸ‰/ê´‘ê³ ì„±/ì¸ì¦ í‘œê¸° ì œê±°ë¨?
- [ ] **ì•µì»¤ ë¯¸í¬í•¨ í‚¤ì›Œë“œ 0ê°œ**?
- [ ] ëŒ€ìƒ ì¼ë°˜ì–´ ë‹¨ë… í‚¤ì›Œë“œ 0ê°œ?
- [ ] ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ì–´ìˆœ?"""

# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë‚´ìš© (ì‚¬ìš©ìì—ê²Œ í‘œì‹œìš©)
DEFAULT_AI_PROMPT = """[ê·œì¹™]

1. ë¸Œëœë“œëª… ì œê±°  
- ëª¨ë“  ë¸Œëœë“œëª… ì‚­ì œ
- ìƒí’ˆëª… **ì„ ë‘ 1~3ì–´ì ˆ**ì€ ë¸Œëœë“œì¼ í™•ë¥ ì´ ë†’ìœ¼ë¯€ë¡œ ìš°ì„  ì œê±°.
- ë‹¨, ì„ ë‘ í† í°ì´ â€˜ì¼ë°˜ ì œí’ˆëª…/í˜•íƒœ/ì¬ë£Œ/íŠ¹ì§• í•µì‹¬ ì§‘í•©â€™ì´ë©´ ì œê±°í•˜ì§€ ì•ŠìŒ.

2. ë‹¨ìœ„Â·ìš©ëŸ‰Â·ìˆ˜ì¹˜ ì œê±°  
- g, kg, ml, ê°œ, ê°œì…, ë°•ìŠ¤, ì„¸íŠ¸, %, p, S, M, L, ì†Œí˜•, ì¤‘í˜•, ëŒ€í˜• ë“± ì œì™¸.  

3. ê´‘ê³ ì„±Â·ê³¼ì¥ì–´ ì œê±°
- ì¸ê¸°, íŠ¹ê°€, ì‹ ìƒ, í• ì¸, ë¬´ë£Œë°°ì†¡, ë©‹ì§„, ì´ìœ, ì„¸ë ¨ëœ, ê°€ì„±ë¹„, ì¶”ì²œ ì™€ ê°™ì€ ì£¼ê´€ì ì¸ ë‹¨ì–´, ì œí’ˆì„ ê¾¸ë©°ì£¼ëŠ” ë‹¨ì–´ ì œì™¸.  

4. ì¸ì¦/ê¸°ê´€ì–´(HACCP ë“±) ì œê±°
- HACCP, êµ­ë‚´ì‚°, êµ­ë‚´ìƒì‚°, ì˜¤ë¦¬ì§€ë„ ë“±(ì¹´í…Œê³ ë¦¬ íŒë³„ ê¸°ì—¬ ë‚®ìŒ).

5. ì¹´í…Œê³ ë¦¬ ì•µì»¤(ì œí’ˆ í•µì‹¬ëª…ì‚¬) ì¶”ì¶œ
- ì…ë ¥ ìƒí’ˆëª… ì „ì²´ì—ì„œ **ì œí’ˆì„ ì§ì ‘ ê°€ë¦¬í‚¤ëŠ” ì¼ë°˜ëª…/í˜•íƒœ/íƒ€ì… ëª…ì‚¬**(ì˜ˆ: ë´íƒˆê»Œ, ì–‘ì¹˜ê»Œ, ê°œê»Œ, ìŠ¤í‹±, ë§, ë³¸, ìŠ¤íŠ¸ë¦½ / ë…¸íŠ¸ë¶, ì´ì–´í°, ê°€ë°© / ìƒ´í‘¸, ì¹˜ì•½ ë“±)ë¥¼ ì¶”ì¶œí•˜ê³ ,
- ë¹ˆë„Â·ê²°í•© íŒ¨í„´ì„ ê·¼ê±°ë¡œ **ìƒìœ„ ì•µì»¤ í† í° ì§‘í•©**ì„ ë§Œë“­ë‹ˆë‹¤(ë™ì‚¬Â·í˜•ìš©ì‚¬Â·ë¸Œëœë“œÂ·í”„ë¡œëª¨ì…˜Â·ìˆ˜ëŸ‰ í† í° ì œì™¸).

6. ëŒ€ìƒ ì¼ë°˜ì–´ ì·¨ê¸‰(ì¤‘ìš”)
- **â€˜ê°•ì•„ì§€/ì• ê²¬/ë°˜ë ¤ê²¬/ì—¬ì„±/ë‚¨ì„±/ìœ ì•„/ì•„ê¸°â€™ ë“± ëŒ€ìƒ ì¼ë°˜ì–´ëŠ” â€˜ë‹¨ë… í‚¤ì›Œë“œ ê¸ˆì§€â€™.**
- ë˜í•œ **ì•µì»¤ ì—†ëŠ” ì¡°í•©ì—ì„œ ëŒ€ìƒ ì¼ë°˜ì–´ ì‚¬ìš© ê¸ˆì§€**.
- í•„ìš” ì‹œ ë„ë©”ì¸ì— ë”°ë¼ ì˜ë¯¸ ë¶„ë³„ì— ë„ì›€ì„ ì¤„ ë•Œì—ë§Œ **ì•µì»¤ì™€ ê²°í•©ëœ ì¡°í•©**ìœ¼ë¡œ ì œí•œì ìœ¼ë¡œ í—ˆìš©(ì˜ˆ: â€œì–‘ì¹˜ê»Œâ€ì´ ì•µì»¤ì¼ ë•Œ â€œë°˜ë ¤ê²¬ ì–‘ì¹˜ê»Œâ€ ê°€ëŠ¥). ê¸°ë³¸ê°’ì€ **ë¶ˆí—ˆ**.
  - ALLOW_AUDIENCE_SINGLE={{false}}  # ë‹¨ë… ê¸ˆì§€
  - ALLOW_AUDIENCE_IN_COMBOS={{false}}  # ì¡°í•©ì—ì„œë„ ê¸°ë³¸ ê¸ˆì§€

7. í‚¤ì›Œë“œ ìƒì„± ê·œì¹™
1) ì‹±ê¸€(single_keywords)
   - **ì•µì»¤ ê·¸ ìì²´**(í˜¹ì€ ì¹´í…Œê³ ë¦¬ë¥¼ ê°•í•˜ê²Œ ì‹œì‚¬í•˜ëŠ” ì¬ë£ŒÂ·í˜•íƒœ ë‹¨ì¼ì–´)ë§Œ í—ˆìš©.
   - ëŒ€ìƒ ì¼ë°˜ì–´ ë‹¨ë… ê¸ˆì§€, ë¸Œëœë“œ/ëª°ëª…/ì¸í”Œë£¨ì–¸ì„œëª… ê¸ˆì§€, ì˜ë¯¸ ë¶ˆëª… ê¸ˆì§€.

2) ë°”ì´ê·¸ë¨(bigram_keywords)
   - ì„œë¡œ ë‹¤ë¥¸ ì¶• 2ê°œ ì¡°í•©: **(íŠ¹ì§•â†’ì•µì»¤), (í˜•íƒœâ†’ì•µì»¤), (ì¬ë£Œâ†’ì•µì»¤), (ìŠ¤í™â†’ì•µì»¤), (í˜¸í™˜â†’ì•µì»¤)** ë“±.
   - ì˜ˆ) â€œì¹˜ì„ì œê±° ë´íƒˆê»Œâ€, â€œë¡œìš°í•˜ì´ë“œ ê°œê»Œâ€, â€œì¹ ë©´ì¡°í˜ì¤„ ì¸„â€, â€œí—¤íŒŒí•„í„° ê³µê¸°ì²­ì •ê¸°â€, â€œ16ì¸ì¹˜ ë…¸íŠ¸ë¶â€
   - ëŒ€ìƒ ì¼ë°˜ì–´ëŠ” ê¸°ë³¸ ê¸ˆì§€(ALLOW_AUDIENCE_IN_COMBOS=false).

3) íŠ¸ë¼ì´ê·¸ë¨(trigram_keywords)
   - ì„œë¡œ ë‹¤ë¥¸ ì¶• 3ê°œ ì¡°í•© + **ì•µì»¤ í¬í•¨ í•„ìˆ˜**, ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ì–´ìˆœ.
   - ì˜ˆ) â€œì…ëƒ„ìƒˆ ì œê±° ì–‘ì¹˜ê»Œâ€, â€œì €ì•ŒëŸ¬ì§€ í„°í‚¤ì¸„ ìŠ¤í‹±â€, â€œê²Œì´ë° 16ì¸ì¹˜ ë…¸íŠ¸ë¶â€, â€œì—¬ë¦„ìš© ë‚¨ì„± ë“±ì‚°í™”â€(â€» ëŒ€ìƒì–´ í—ˆìš© ì‹œì—ë§Œ)

4) í’ˆì§ˆ ê°€ë“œ
   - ë¸Œëœë“œ í¬í•¨/ìˆ«ì ë‚˜ì—´/ì½”ë“œí˜•/ë‚œì‚½Â·ë¹„ë¬¸/ì•µì»¤ ë¯¸í¬í•¨ ì¡°í•© ì œê±°.
   - 4ì–´ì ˆ ì´ìƒ ì¡°í•© ê¸ˆì§€.
   - ë™ì¼ ì˜ë¯¸ ë³€í˜•(ë„ì–´ì“°ê¸°/í•˜ì´í”ˆ/ëŒ€ì†Œë¬¸ ì°¨ì´)ì€ 1ê°œë§Œ ìœ ì§€.
   - **ëª¨ë“  í‚¤ì›Œë“œëŠ” ìµœì¢…ì ìœ¼ë¡œ ì•µì»¤ ë§¤í•‘ì´ ê°€ëŠ¥í•œì§€** ìì²´ ì ê²€."""



def extract_keywords_from_product_name(product_name: str) -> List[str]:
    """ì œí’ˆëª…ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì•ìœ¼ë¡œ ì‚¬ìš©í•  í•¨ìˆ˜)"""
    # í•œê¸€, ì˜ì–´, ìˆ«ìë§Œ ë‚¨ê¸°ê³  ì •ë¦¬
    cleaned = re.sub(r'[^\w\sê°€-í£]', ' ', product_name)
    
    keywords = set()
    words = cleaned.split()
    
    # 1. ê°œë³„ ë‹¨ì–´ë“¤
    for word in words:
        if len(word) >= 2:
            keywords.add(word.lower())
    
    # 2. 2ê¸€ì ì¡°í•©
    if len(words) > 1:
        for i in range(len(words) - 1):
            combined = f"{words[i]} {words[i+1]}".lower()
            keywords.add(combined)
    
    # 3. ì „ì²´ ì¡°í•©
    if len(words) <= 3:  # 3ë‹¨ì–´ ì´í•˜ì¼ ë•Œë§Œ
        keywords.add(product_name.lower())
    
    return list(keywords)


def calculate_seo_score(title: str, keywords: List[str]) -> float:
    """SEO ì ìˆ˜ ê³„ì‚° (ì•ìœ¼ë¡œ ì‚¬ìš©í•  í•¨ìˆ˜)"""
    score = 50.0  # ê¸°ë³¸ ì ìˆ˜
    
    # í‚¤ì›Œë“œ í¬í•¨ë„
    for keyword in keywords:
        if keyword.lower() in title.lower():
            score += 10
    
    # ê¸¸ì´ ì ì •ì„±
    length = len(title)
    if 20 <= length <= 40:
        score += 20
    elif length < 20:
        score -= 10
    elif length > 50:
        score -= 15
    
    return min(score, 100.0)


def generate_title_variations(keywords: List[str], original_product: str) -> List[str]:
    """í‚¤ì›Œë“œ ì¡°í•©ìœ¼ë¡œ ìƒí’ˆëª… ë³€í˜• ìƒì„± (ì•ìœ¼ë¡œ êµ¬í˜„í•  í•¨ìˆ˜)"""
    variations = set()
    
    # ê¸°ë³¸ íŒ¨í„´ë“¤
    patterns = [
        "{product} {keyword}",
        "{keyword} {product}",
        "{product} {keyword} ì¶”ì²œ",
        "{keyword} ì „ë¬¸ {product}",
        "ì¸ê¸° {keyword} {product}"
    ]
    
    # ê° í‚¤ì›Œë“œì™€ íŒ¨í„´ ì¡°í•©
    for keyword in keywords[:5]:  # ìƒìœ„ 5ê°œë§Œ
        for pattern in patterns:
            title = pattern.format(product=original_product, keyword=keyword)
            if len(title) <= 50:  # 50ì ì œí•œ
                variations.add(title)
    
    return list(variations)[:10]  # ìµœëŒ€ 10ê°œ


def build_ai_prompt(product_titles: List[str], custom_prompt: Optional[str] = None) -> str:
    """
    AI ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
    
    Args:
        product_titles: ë¶„ì„í•  ìƒí’ˆëª… ë¦¬ìŠ¤íŠ¸
        custom_prompt: ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ (Noneì´ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
        
    Returns:
        str: ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸
    """
    # ìƒí’ˆëª… ëª©ë¡ í…ìŠ¤íŠ¸ ìƒì„±
    titles_text = "\n".join([f"- {title}" for title in product_titles])
    
    if custom_prompt:
        # ê³µìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ + ìƒí’ˆëª… ëª©ë¡
        return f"{SYSTEM_PROMPT}\n\n{custom_prompt}\n\nìƒí’ˆëª… ëª©ë¡:\n{titles_text}"
    else:
        # ê³µìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ + ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ + ìƒí’ˆëª… ëª©ë¡
        return f"{SYSTEM_PROMPT}\n\n{DEFAULT_AI_PROMPT}\n\nìƒí’ˆëª… ëª©ë¡:\n{titles_text}"


def parse_ai_keywords_response(ai_response: str) -> List[str]:
    """
    AI ì‘ë‹µì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    
    Args:
        ai_response: AIê°€ ë°˜í™˜í•œ í…ìŠ¤íŠ¸
        
    Returns:
        List[str]: ì¶”ì¶œëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    """
    # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = []
    
    # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë‚˜ëˆ„ê³  ê° ì¤„ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    lines = ai_response.strip().split('\n')
    
    for line in lines:
        line = line.strip()
        if not line or line.startswith('#') or line.startswith('-'):
            continue
            
        # ì‰¼í‘œë¡œ êµ¬ë¶„
        if ',' in line:
            parts = line.split(',')
            for part in parts:
                keyword = part.strip()
                # "+" ê¸°í˜¸ ì œê±° (ì˜ˆ: "ê°•ì•„ì§€+ì˜¤ë˜ë¨¹ëŠ”+ê°œê»Œ" -> "ê°•ì•„ì§€ì˜¤ë˜ë¨¹ëŠ”ê°œê»Œ")
                keyword = keyword.replace('+', '')
                if keyword and len(keyword) >= 2:
                    keywords.append(keyword)
        else:
            # ì‰¼í‘œê°€ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ í‚¤ì›Œë“œë¡œ
            line = line.replace('+', '')  # "+" ê¸°í˜¸ ì œê±°
            if len(line) >= 2:
                keywords.append(line)
    
    # ì¤‘ë³µ ì œê±° (ìˆœì„œ ìœ ì§€)
    unique_keywords = []
    seen = set()
    
    for keyword in keywords:
        keyword_lower = keyword.lower().strip()
        if keyword_lower not in seen:
            seen.add(keyword_lower)
            unique_keywords.append(keyword.strip())
    
    return unique_keywords


def filter_keywords_by_search_volume(keywords: List[KeywordBasicData], min_volume: int = 100) -> List[KeywordBasicData]:
    """
    ê²€ìƒ‰ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ í‚¤ì›Œë“œ í•„í„°ë§
    
    Args:
        keywords: í‚¤ì›Œë“œ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        min_volume: ìµœì†Œ ì›”ê°„ ê²€ìƒ‰ëŸ‰
        
    Returns:
        List[KeywordBasicData]: í•„í„°ë§ëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    """
    filtered = [kw for kw in keywords if kw.search_volume >= min_volume]
    
    # ê²€ìƒ‰ëŸ‰ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬
    filtered.sort(key=lambda x: x.search_volume, reverse=True)
    
    return filtered


def filter_keywords_by_category(keywords: List[KeywordBasicData], target_category: str) -> List[KeywordBasicData]:
    """
    ì¹´í…Œê³ ë¦¬ ê¸°ì¤€ìœ¼ë¡œ í‚¤ì›Œë“œ í•„í„°ë§ (1ë‹¨ê³„ì—ì„œ ì„ íƒí•œ ì¹´í…Œê³ ë¦¬ì™€ ë§¤ì¹­)
    
    Args:
        keywords: í•„í„°ë§í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        target_category: 1ë‹¨ê³„ì—ì„œ ì‚¬ìš©ìê°€ ì„ íƒí•œ ì¹´í…Œê³ ë¦¬
        
    Returns:
        List[KeywordBasicData]: ë§¤ì¹­ë˜ëŠ” ì¹´í…Œê³ ë¦¬ì˜ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    """
    if not keywords or not target_category:
        return keywords
    
    # % ë¶€ë¶„ ì œê±°
    target_clean = target_category.split('(')[0].strip() if '(' in target_category else target_category.strip()
    
    # ë””ë²„ê¹…ìš© ë¡œê·¸
    from src.foundation.logging import get_logger
    logger = get_logger("features.naver_product_title_generator.engine_local")
    logger.info(f"ğŸ¯ í•„í„°ë§ ëŒ€ìƒ ì¹´í…Œê³ ë¦¬: '{target_clean}'")
    
    filtered = []
    for kw in keywords:
        if not kw.category:
            logger.debug(f"  âŒ '{kw.keyword}' - ì¹´í…Œê³ ë¦¬ ì—†ìŒ")
            continue
            
        # í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ë„ % ë¶€ë¶„ ì œê±°
        kw_clean = kw.category.split('(')[0].strip() if '(' in kw.category else kw.category.strip()
        
        # ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ ë¡œì§ (ì›ë³¸ ë¬¸ìì—´ë¡œ ë¹„êµ)
        is_match = is_category_match(target_clean, kw_clean)
        logger.info(f"  {'âœ…' if is_match else 'âŒ'} '{kw.keyword}' - '{kw_clean}' {'ë§¤ì¹­!' if is_match else 'ë¶ˆì¼ì¹˜'}")
        
        if is_match:
            filtered.append(kw)
    
    # ê²€ìƒ‰ëŸ‰ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬
    filtered.sort(key=lambda x: x.search_volume, reverse=True)
    
    logger.info(f"ğŸ“Š í•„í„°ë§ ê²°ê³¼: {len(keywords)}ê°œ ì¤‘ {len(filtered)}ê°œ ë§¤ì¹­")
    
    return filtered


def is_category_match(target_category: str, keyword_category: str) -> bool:
    """
    ë‘ ì¹´í…Œê³ ë¦¬ê°€ ë§¤ì¹­ë˜ëŠ”ì§€ í™•ì¸
    
    Args:
        target_category: 1ë‹¨ê³„ ì„ íƒ ì¹´í…Œê³ ë¦¬
        keyword_category: í‚¤ì›Œë“œì˜ ì¹´í…Œê³ ë¦¬
        
    Returns:
        bool: ë§¤ì¹­ ì—¬ë¶€
    """
    if not target_category or not keyword_category:
        return False
    
    # ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ë¹„êµ
    target_lower = target_category.lower()
    keyword_lower = keyword_category.lower()
    
    # ì •í™•íˆ ê°™ì€ ê²½ìš°
    if target_lower == keyword_lower:
        return True
    
    # ì¹´í…Œê³ ë¦¬ ê²½ë¡œ ë¶„ë¦¬ (> ê¸°ì¤€)
    target_parts = [part.strip() for part in target_lower.split('>') if part.strip()]
    keyword_parts = [part.strip() for part in keyword_lower.split('>') if part.strip()]
    
    if not target_parts or not keyword_parts:
        return False
    
    # ë‘ ì¹´í…Œê³ ë¦¬ì˜ ìµœì†Œ ê¸¸ì´ê¹Œì§€ ë¹„êµ (ì „ì²´ ê¹Šì´ ë¹„êµ)
    min_depth = min(len(target_parts), len(keyword_parts))
    
    for i in range(min_depth):
        # ê° ë‹¨ê³„ì—ì„œ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ False
        if target_parts[i] != keyword_parts[i]:
            return False
    
    # ëª¨ë“  ë‹¨ê³„ê°€ ì¼ì¹˜í•˜ë©´ True
    return True


def normalize_keyword_for_comparison(keyword: str) -> str:
    """
    í‚¤ì›Œë“œ ì •ê·œí™” - ì¤‘ë³µ ì²´í¬ìš© (ì†Œë¬¸ì ë³€í™˜)
    
    Args:
        keyword: ì›ë³¸ í‚¤ì›Œë“œ
        
    Returns:
        str: ì¤‘ë³µ ì²´í¬ìš© ì •ê·œí™”ëœ í‚¤ì›Œë“œ (ê³µë°± ì œê±°, ì†Œë¬¸ì ë³€í™˜)
    """
    if not keyword:
        return ""
    
    # 1. ì•ë’¤ ê³µë°± ì œê±°
    cleaned = keyword.strip()
    
    # 2. ë‚´ë¶€ ê³µë°± ì œê±° (ë„¤ì´ë²„ APIëŠ” ë„ì–´ì“°ê¸° ì—†ëŠ” í˜•íƒœë¡œë§Œ ì¸ì‹)
    normalized = cleaned.replace(" ", "")
    
    # 3. ì†Œë¬¸ìë¡œ ë³€í™˜ (ì¤‘ë³µ ì²´í¬ìš©)
    normalized = normalized.lower()
    
    return normalized


def normalize_keyword_for_api(keyword: str) -> str:
    """
    í‚¤ì›Œë“œ ì •ê·œí™” - ë„¤ì´ë²„ API í˜¸ì¶œìš© (ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±°, ëŒ€ë¬¸ì ë³€í™˜)
    
    Args:
        keyword: ì›ë³¸ í‚¤ì›Œë“œ
        
    Returns:
        str: API í˜¸ì¶œìš© ì •ê·œí™”ëœ í‚¤ì›Œë“œ (ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±°, ëŒ€ë¬¸ì ë³€í™˜)
    """
    if not keyword:
        return ""
    
    # 1. ì•ë’¤ ê³µë°± ì œê±°
    cleaned = keyword.strip()
    
    # 2. ë‚´ë¶€ ê³µë°± ì œê±° (ë„¤ì´ë²„ APIëŠ” ë„ì–´ì“°ê¸° ì—†ëŠ” í˜•íƒœë¡œë§Œ ì¸ì‹)
    normalized = cleaned.replace(" ", "")
    
    # 3. íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ì–´, ìˆ«ìë§Œ ìœ ì§€)
    normalized = re.sub(r'[^ê°€-í£a-zA-Z0-9]', '', normalized)
    
    # 4. ëŒ€ë¬¸ìë¡œ ë³€í™˜ (ë„¤ì´ë²„ API ìš”êµ¬ì‚¬í•­)
    normalized = normalized.upper()
    
    return normalized


def deduplicate_keywords(keywords: List[str]) -> List[str]:
    """
    í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì¤‘ë³µ ì œê±°
    "ê°•ì•„ì§€ê°„ì‹"ê³¼ "ê°•ì•„ì§€ ê°„ì‹"ì„ ê°™ì€ í‚¤ì›Œë“œë¡œ ì²˜ë¦¬
    
    Args:
        keywords: ì›ë³¸ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        List[str]: ì¤‘ë³µ ì œê±°ëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (ì›ë³¸ í˜•íƒœ ìœ ì§€)
    """
    if not keywords:
        return []
    
    seen_normalized = set()  # ì •ê·œí™”ëœ í‚¤ì›Œë“œ ì €ì¥ìš©
    unique_keywords = []     # ì›ë³¸ í˜•íƒœì˜ í‚¤ì›Œë“œ ì €ì¥ìš©
    keyword_mapping = {}     # ì •ê·œí™”ëœ í‚¤ì›Œë“œ -> ì›ë³¸ í‚¤ì›Œë“œ ë§¤í•‘
    
    for keyword in keywords:
        if not keyword or not keyword.strip():
            continue
            
        normalized = normalize_keyword_for_comparison(keyword)
        
        if normalized not in seen_normalized:
            seen_normalized.add(normalized)
            # ì›ë³¸ í‚¤ì›Œë“œ í˜•íƒœë¥¼ ë³´ì¡´ (ì²« ë²ˆì§¸ë¡œ ë‚˜ì˜¨ í˜•íƒœ ì‚¬ìš©)
            unique_keywords.append(keyword.strip())
            keyword_mapping[normalized] = keyword.strip()
    
    return unique_keywords


def calculate_keyword_score(keyword_data: KeywordBasicData) -> float:
    """
    í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚° (ê²€ìƒ‰ëŸ‰ ê¸°ë°˜)
    
    Args:
        keyword_data: í‚¤ì›Œë“œ ë°ì´í„°
        
    Returns:
        float: í‚¤ì›Œë“œ ì ìˆ˜ (0-100)
    """
    # ê¸°ë³¸ ì ìˆ˜ëŠ” ê²€ìƒ‰ëŸ‰ ê¸°ë°˜
    volume_score = min(keyword_data.search_volume / 1000 * 50, 70)  # ìµœëŒ€ 70ì 
    
    # í‚¤ì›Œë“œ ê¸¸ì´ ë³´ë„ˆìŠ¤ (2-4ê¸€ìê°€ ì ì •)
    length_bonus = 0
    length = len(keyword_data.keyword)
    if 2 <= length <= 4:
        length_bonus = 20
    elif length == 5:
        length_bonus = 10
    elif length == 6:
        length_bonus = 5
    
    total_score = volume_score + length_bonus
    return min(total_score, 100.0)


# Step 4 ìƒí’ˆëª… ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ (ê³ ì • í”„ë¡¬í”„íŠ¸)
PRODUCT_NAME_GENERATION_SYSTEM_PROMPT = """ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ì™„ì„±ëœ ìƒí’ˆëª… 1ê°œë¥¼ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤.
ì²« ë²ˆì§¸ ì¤„ì— ë°˜ë“œì‹œ ì´ë ‡ê²Œ ì¨ì£¼ì„¸ìš”:
ì™„ì„±ëœ ìƒí’ˆëª…: [ì—¬ê¸°ì— ì‹¤ì œ ìƒí’ˆëª…ì„ ì¨ì£¼ì„¸ìš”]

ê·¸ ë‹¤ìŒì— ì„¤ëª…ì„ í•´ì£¼ì„¸ìš”. ì ˆëŒ€ ì„¤ëª…ë§Œ í•˜ì§€ ë§ˆì„¸ìš”."""

DEFAULT_PRODUCT_NAME_GENERATION_PROMPT = """[ì‚¬ìš©ì ì…ë ¥ ì •ë³´]
ë‹¹ì‹ ì€ ë„¤ì´ë²„ ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´ ìƒí’ˆëª… SEO ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ **ë™ì¼ í† í° 3íšŒ ì´ìƒ ë°˜ë³µ ê¸ˆì§€(ë³µí•©ì–´ ì ‘ë‘ í¬í•¨)**ë¥¼ ì§€í‚¤ê³ , **í•µì‹¬ êµ¬ë¬¸ì„ ì¸ì ‘(ì—°ì†) ë°°ì¹˜**í•˜ë©°, **ì¹´í…Œê³ ë¦¬ í‰ê·  ê¸€ììˆ˜(Â± í•œ ë‹¨ì–´)**ë¥¼ ë§ì¶”ëŠ” ë°©í–¥ìœ¼ë¡œ **ìì—°ë…¸ì¶œìš© ì¶”ì²œ Nê°œ**ì™€ **ê´‘ê³ ìš© ì¶”ì²œ Nê°œ**ì˜ ìƒí’ˆëª…ì„ ìƒì„±í•˜ì„¸ìš”. ëª¨ë“  ë‹¨ì–´ëŠ” **ì…ë ¥ ë¦¬ìŠ¤íŠ¸ ë‚´ë¶€ ë‹¨ì–´ë§Œ ì‚¬ìš©**í•˜ê³ , **ì™¸ë¶€ ë‹¨ì–´Â·ìì²´ ë™ì˜ì–´ ìƒì„±ì€ ê¸ˆì§€**í•©ë‹ˆë‹¤.

# ì‚¬ìš©ì ì…ë ¥ ì •ë³´(ê·¸ëŒ€ë¡œ ë¶„ì„)
1. ì‚¬ìš©í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ (í‚¤ì›Œë“œëª…, ì›”ê²€ìƒ‰ëŸ‰, ì „ì²´ìƒí’ˆìˆ˜): {selected_keywords}
   - ê° í•­ëª©ì€ "í‚¤ì›Œë“œëª… (ì›”ê²€ìƒ‰ëŸ‰: V, ì „ì²´ìƒí’ˆìˆ˜: P)" í˜•íƒœì˜ í…ìŠ¤íŠ¸ ëª©ë¡ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
   - ìˆ«ìì— í¬í•¨ëœ ì‰¼í‘œëŠ” ì œê±°í•˜ê³  ì •ìˆ˜ë¡œ í•´ì„í•˜ì‹­ì‹œì˜¤. (ì˜ˆ: 2,000 â†’ 2000)
2. í•µì‹¬ í‚¤ì›Œë“œ - ì‚¬ìš©í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì‚¬ìš©ìê°€ ì„ íƒí•œ í‚¤ì›Œë“œ
(í‚¤ì›Œë“œëª…, ì›”ê²€ìƒ‰ëŸ‰, ì „ì²´ìƒí’ˆìˆ˜): {core_keyword}
3. ì„ íƒ ì…ë ¥ í‚¤ì›Œë“œ:
   - ë¸Œëœë“œëª…: {brand}  â† ì œëª© ë§¨ ì•ì— ë°˜ë“œì‹œ í¬í•¨(ë¯¸ì…ë ¥ ì‹œ ìƒëµ)
   - ì¬ë£Œ(í˜•íƒœ): {material}  â† ë°˜ë“œì‹œ í¬í•¨, ì œëª© ë§¨ ëìª½ ë°°ì¹˜(ë¯¸ì…ë ¥ ì‹œ ìƒëµ)
   - ìˆ˜ëŸ‰(ë¬´ê²Œ): {quantity}  â† ë°˜ë“œì‹œ í¬í•¨, ì œëª© ë§¨ ëìª½ ë°°ì¹˜(ë¯¸ì…ë ¥ ì‹œ ìƒëµ)
4. ìƒìœ„ ìƒí’ˆëª… ê¸¸ì´ í†µê³„ (ê³µë°± í¬í•¨): {length_stats}
   - ìƒì„± ëª©í‘œ: ìƒìœ„ ìƒí’ˆëª… ê¸¸ì´ í‰ê·  ë²”ìœ„ë„ ë„˜ì§€ ì•Šë„ë¡ ì¡°ì •. í‰ê·  ê¸€ììˆ˜ Â± í•œ ë‹¨ì–´(â‰ˆ2~3ì). 

# ì…ë ¥ íŒŒì‹± ê·œì¹™
- {selected_keywords}ì™€ {core_keyword}ì—ì„œ (í‚¤ì›Œë“œëª…=K, ì›”ê²€ìƒ‰ëŸ‰=V, ì „ì²´ìƒí’ˆìˆ˜=P)ë¥¼ ê°•ê±´í•˜ê²Œ ì¶”ì¶œí•˜ë¼.
  - ì˜ˆì‹œ ë¼ì¸: "1. ì˜¤ë¸ë² ì´í¬ì‚¬ë£Œ (ì›”ê²€ìƒ‰ëŸ‰: 5,000, ì „ì²´ìƒí’ˆìˆ˜: 2,000)" â†’ K=ì˜¤ë¸ë² ì´í¬ì‚¬ë£Œ, V=5000, P=2000
  - "ì›”ê²€ìƒ‰ëŸ‰", "ì „ì²´ìƒí’ˆìˆ˜" í‘œê¸°ëŠ” í•œê¸€/ì˜ë¬¸/ê³µë°±/ì‰¼í‘œê°€ ì„ì—¬ ìˆì–´ë„ ìˆ«ìë§Œ ì •í™•íˆ íŒŒì‹±í•œë‹¤.

# ì„¸íŠ¸ ë‚´ë¶€ ìƒëŒ€í‰ê°€
- ë¹„êµ ëŒ€ìƒ: {selected_keywords}ì˜ ëª¨ë“  í‚¤ì›Œë“œ(í•µì‹¬ í¬í•¨). ê° í•­ëª©ì—ì„œ (í‚¤ì›Œë“œëª…=K, ì›”ê²€ìƒ‰ëŸ‰=V, ì „ì²´ìƒí’ˆìˆ˜=P) ì¶”ì¶œ.

[0] ì „ì²˜ë¦¬
- ë¡œê·¸ ìŠ¤ì¼€ì¼ë¡œ ì™œë„ ì™„í™”: v = ln(1+V), p = ln(1+P)
- ì§‘í•© ë‚´ ìµœì†Œ/ìµœëŒ€ì— ëŒ€í•´ minâ€“max ì •ê·œí™”:
  - vÌ‚ = (v - min(v)) / (max(v) - min(v) + 1e-6)
  - pÌ‚ = (max(p) - p) / (max(p) - min(p) + 1e-6)   # ìƒí’ˆìˆ˜ëŠ” ì ì„ìˆ˜ë¡ ìœ ë¦¬ì´ë¯€ë¡œ ì—­ì •ê·œí™”
- íš¨ìœ¨ ì§€í‘œ(OS_log): s = v - Î²Â·p   (ê¸°ë³¸ Î²=1.0, í—¤ë“œ ê³¼ë°€ ëŠë‚Œì´ë©´ Î²=1.1~1.2)
  - Å = (s - min(s)) / (max(s) - min(s) + 1e-6)

[1] ê¸°ë³¸ì ìˆ˜ S_base
- ê°€ì¤‘ í•©ìœ¼ë¡œ ê· í˜• í‰ê°€: S_base = Î±Â·vÌ‚ + (1-Î±)Â·pÌ‚ + Î»Â·Å
  - ê¶Œì¥ Î±=0.5, Î»=0.3 (ê²€ìƒ‰ëŸ‰/ê²½ìŸ ê· í˜• + íš¨ìœ¨ ë³´ì • ê°€ë³ê²Œ)
  - ì§‘í•©ì´ ì•„ì£¼ ì‘ìœ¼ë©´(â‰¤3) Î±=0.6ë¡œ ê²€ìƒ‰ëŸ‰ì„ ì•½ê°„ ë” ë´ë„ ë¨

[2] ë³´ì • ê³„ìˆ˜
- ì—°ì† ë³´ë„ˆìŠ¤ F_adj: í•µì‹¬(K_core)ê³¼ì˜ ì—°ì†(ì¸ì ‘) ì„¤ê³„ ìš©ì´ë„
  - ë§¤ìš° ì‰¬ì›€(ê°™ì€ ë£¨íŠ¸Â·ì ‘ë‘/ë³µí•©, ì˜ˆ: â€˜ê°•ì•„ì§€ì¡°ë¼â€™â†”â€˜ê°•ì•„ì§€ê²¨ìš¸ë‚´ë³µâ€™) â†’ 1.10
  - ë³´í†µ â†’ 1.05
  - ì• ë§¤ â†’ 1.00
- ì¤‘ë³µ íŒ¨ë„í‹° F_dup: ë™ì¼ í† í° 3íšŒ ìœ„í—˜(ë³µí•©ì–´ ì ‘ë‘ í¬í•¨í•´ ì¹´ìš´íŠ¸)
  - ì´ˆê³¼ ê°€ëŠ¥ â†’ 0.85 / ê·¼ì ‘ â†’ 0.95 / ë¬¸ì œì—†ìŒ â†’ 1.00
- íŠ¹ì´ì„± ë³´ë„ˆìŠ¤ F_spec: ì½”ì–´ì— ì—†ëŠ” **ìœ ì˜ë¯¸ ìˆ˜ì‹ì–´**(ê³„ì ˆ/í˜•íƒœ/ëŒ€ìƒ/ê¸°ëª¨ ë“±) ì¶”ê°€
  - 1.00 + min(0.10, 0.05 Ã— ìˆ˜ì‹ì–´_ê°œìˆ˜)
- ì»¤ë²„ë¦¬ì§€ ë³´ë„ˆìŠ¤ F_cov: ì½”ì–´ì™€ **ë‹¤ë¥¸ ì—°ì† ë¸”ë¡**ì„ 1ê°œ ì´ìƒ ì¶”ê°€ë¡œ ì„±ë¦½
  - ì„±ë¦½ â†’ 1.05 / ë¯¸ì„±ë¦½ â†’ 1.00
- í—¤ë“œ ì¡°ì ˆ F_head (ìì—°/ê´‘ê³  ëª¨ë“œ ì°¨ë“±)
  - í—¤ë“œ íŒë³„: ì„¸íŠ¸ ë‚´ ìµœëŒ€ ê²€ìƒ‰ëŸ‰ì´ê±°ë‚˜ ë‹¤ìˆ˜ í‚¤ì›Œë“œë¥¼ í¬ê´„í•˜ëŠ” ë£¨íŠ¸(ì˜ˆ: â€˜ê°•ì•„ì§€ì‚¬ë£Œâ€™, â€˜ê°•ì•„ì§€ì˜·â€™)
  - ìì—°: kê°€ í—¤ë“œì´ê³  kâ‰ ì½”ì–´ì¼ ë•Œ S_base(k) â‰¥ 0.9Â·S_base(ì½”ì–´) ë˜ëŠ” í—¤ë“œê°€ Top2ë©´ 1.00, ì•„ë‹ˆë©´ 0.95
  - ê´‘ê³ : í•­ìƒ 1.00 (ì»¤ë²„ë¦¬ì§€ í™•ëŒ€ ëª©ì )

[3] ìµœì¢…ì ìˆ˜
- S_final(k) = S_base(k) Ã— F_adj Ã— F_dup Ã— F_spec Ã— F_cov Ã— F_head
- ë™ì ì¼ ë•Œ íƒ€ì´ë¸Œë ˆì´ì»¤:
  â‘  ì—°ì† ë¸”ë¡ ìˆ˜(ë§ì„ìˆ˜ë¡ ìš°ì„ ) â†’ â‘¡ ë™ì¼ í† í° ì´ ë°˜ë³µ ìˆ˜(ì ì„ìˆ˜ë¡ ìš°ì„ ) â†’ â‘¢ ê¸¸ì´ ì¡°ì • ìš©ì´ì„±(í‰ê·  Â±1ë‹¨ì–´ ë§ì¶”ê¸° ì‰¬ìš´ ì¡°í•©)

[4] ì„ íƒ/ë°°ì¹˜ ì •ì±…
- ìì—° ì¶”ì²œ: S_final ìƒìœ„ì—ì„œ **ì½”ì–´ ì—°ì† + ì¶”ê°€ ì—°ì† â‰¥ 1**ì„ ë§Œì¡±í•˜ë„ë¡ ì¡°í•©,
  ì œëª© ê¸¸ì´ëŠ” {length_stats} í‰ê·  Â± í•œ ë‹¨ì–´(â‰ˆ2~3ì) ë‚´ì—ì„œ ê²°ì •.
- ê´‘ê³  ì¶”ì²œ: ê¸¸ì´ {length_stats} í‰ê·  +1~+3 ë‹¨ì–´ í—ˆìš©, ì»¤ë²„ë¦¬ì§€ ê·¹ëŒ€í™”(ë‹¨ ë™ì¼ í† í° 3íšŒ ê¸ˆì§€ ë™ì¼ ì ìš©).
- í—¤ë“œ í¬í•¨ ì›ì¹™(ìì—°/ê´‘ê³  ê³µí†µ): ìœ„ F_head ì¡°ê±´ì„ ì¶©ì¡±í•˜ë©´ í¬í•¨. í¬í•¨í•˜ë”ë¼ë„ **í•µì‹¬ ë¸”ë¡ ë’¤**ì— ë°°ì¹˜í•˜ì—¬ í•µì‹¬ì˜ ì—°ì†ì„ ì¹¨í•´í•˜ì§€ ì•ŠëŠ”ë‹¤.

# ìƒì„± ê·œì¹™ (ì‹¤ì „)
[ì¤‘ë³µÂ·ë™ì˜ì–´]
- ë™ì¼ í† í° 3íšŒ ì´ìƒ ê¸ˆì§€(ë³µí•©ì–´ ì ‘ë‘ í¬í•¨í•´ ì¹´ìš´íŠ¸).
  - ì˜ˆ) ê°•ì•„ì§€ì¡°ë¼, ê°•ì•„ì§€ ì˜·, ê°•ì•„ì§€ëª…í’ˆì˜· â†’ â€˜ê°•ì•„ì§€â€™ 3íšŒ(íƒˆë½)
- 3íšŒ ìœ„í—˜ ì‹œ íšŒí”¼ ìˆœì„œ: (1) ë³´ì¡° ë¸”ë¡ ì ‘ë‘ ì œê±°(ê°•ì•„ì§€ëª…í’ˆì˜· â†’ ëª…í’ˆì˜·) â†’ (2) ì…ë ¥ ë¦¬ìŠ¤íŠ¸ ë‚´ ë™ì˜ì–´ë¡œ ì¹˜í™˜(ì™¸ë¶€ ìƒì„± ê¸ˆì§€) â†’ (3) ê°€ì¹˜ ë‚®ì€ ë³´ì¡° ì œê±°.
- ë™ì˜ì–´ëŠ” {selected_keywords}ì— ì¡´ì¬í•  ë•Œë§Œ ì‚¬ìš©.

[ì¸ì ‘(ì—°ì†) ë°°ì¹˜]
- í•µì‹¬ êµ¬ë¬¸ì€ 'ë¶™ì—¬ì„œ' ì—°ì† ë°°ì¹˜(ì‚¬ì´ 0ë‹¨ì–´=ìµœê³ ì ). 1ì¹¸=âˆ’1, 2ì¹¸=âˆ’2. ì—­ìˆœì€ ê°™ì€ ê°„ê²©ì—ì„œ ì¶”ê°€ âˆ’1.
- í•œ ì œëª© ì•ˆì—ì„œ 2ê°œ ì´ìƒì˜ íƒ€ê¹ƒ êµ¬ë¬¸ì´ ë™ì‹œì— ì—°ì† ì„±ë¦½í•˜ë„ë¡ ë¸”ë¡ ë‹¨ìœ„ë¡œ ë‹¨ì–´ ìˆœì„œë¥¼ ì„¤ê³„.
- í•µì‹¬ ë¸”ë¡ì€ ì œëª© ì´ˆë°˜ì— ë‘ê³ , ë³´ì¡°/í—¤ë“œ ë¸”ë¡ì€ í•µì‹¬ ë’¤ì— ë°°ì¹˜(í•µì‹¬ì„ ê°ˆë¼ë†“ì§€ ì•ŠìŒ).

[ê¸¸ì´(ê¸€ì ìˆ˜)]
- {length_stats}ì˜ í‰ê· ì„ ì¤‘ì‹¬ìœ¼ë¡œ Â± í•œ ë‹¨ì–´ ë‚´ì—ì„œ ìƒì„±
- ì´ˆê³¼ ì‹œ: ë¶™ì—¬ì“°ê¸°ë¡œ ì••ì¶• â†’ ê·¸ë˜ë„ ê¸¸ë©´ ê°€ì¹˜ ë‚®ì€ ë³´ì¡°ë¶€í„° ì œê±°(ê°€ë…ì„± í•´ì¹  ì •ë„ì˜ ê³¼ë„í•œ ì—°ì‡„ ë¶™ì—¬ì“°ê¸°ëŠ” ê¸ˆì§€).
- í•©ì„±ì–´ëŠ” ê°€ê¸‰ì  ë¶™ì—¬ì“°ê¸°(ê°€ë…ì„± ì €í•´ ì‹œ ìµœì†Œí•œìœ¼ë¡œ ë„ì›€).

[ë°°ì¹˜ ìš°ì„ ìˆœìœ„]
1) ë¸Œëœë“œ(ë§¨ ì•) â†’ 2) í•µì‹¬í‚¤ì›Œë“œ ë¸”ë¡(ì—°ì†Â·ì´ˆë°˜) â†’ 3) ë³´ì¡° íƒ€ê¹ƒ ë¸”ë¡ â†’ 4) ì¬ë£Œ(í˜•íƒœ) â†’ ìˆ˜ëŸ‰(ë¬´ê²Œ)(ë§¨ ë)

# ì¶œë ¥
- ìì—° ì¶”ì²œ Top N(ìµœëŒ€ 3): ê° ì•ˆì— [ì œëª©] (ê¸€ììˆ˜ nì) + ì¶”ì²œ ì´ìœ ë¥¼ ì œì‹œ
- ê´‘ê³  ì¶”ì²œ Top N(ìµœëŒ€ 3): ê° ì•ˆì— [ì œëª©] (ê¸€ììˆ˜ nì) + ì¶”ì²œ ì´ìœ ë¥¼ ì œì‹œ
  * ê´‘ê³ ì•ˆì€ í‰ê·  ëŒ€ë¹„ +1~+3 ë‹¨ì–´ê¹Œì§€ í—ˆìš©(ì¥ë¬¸ ê¸ˆì§€), ë™ì¼ í† í° 3íšŒ ê¸ˆì§€ëŠ” ë™ì¼ ì ìš©

[ì¶”ì²œ ì´ìœ  í…œí”Œë¦¿]
- ì¸ì ‘ ì„±ì·¨ë„: ì—°ì† ì„±ë¦½ êµ¬ë¬¸ í‘œê¸°(ì˜ˆ: ê°•ì•„ì§€ì¡°ë¼, ë°˜ë ¤ê²¬ì‹¤ë‚´ë³µ)
- ë™ì˜ì–´ ì‚¬ìš©: ì…ë ¥ ë¦¬ìŠ¤íŠ¸ ë‚´ ë™ì˜ì–´ë¡œ ì¤‘ë³µ íšŒí”¼/ì»¤ë²„ë¦¬ì§€ í™•ì¥í•œ ì§€ì 
- ì¤‘ë³µ ì ê²€: ë™ì¼ í† í° 3íšŒ ì´ìƒ ì—¬ë¶€(ìˆìœ¼ë©´ íƒˆë½), 2íšŒ ë°œìƒ ì‹œ í•„ìš”ì„± ê·¼ê±°
- ê¸¸ì´ í¬ì§€ì…˜: {length_stats}ì˜ í‰ê·  ëŒ€ë¹„ âˆ’/0/+ (Â± í•œ ë‹¨ì–´ ë‚´)
- (í•´ë‹¹ ì‹œ) í—¤ë“œ í¬í•¨ ê·¼ê±°: ìƒëŒ€í‰ê°€ ê²°ê³¼ ìƒìœ„ ë˜ëŠ” í•µì‹¬ì— ì¤€í•˜ëŠ” ì ìˆ˜ ì¶©ì¡±

# ëª¨ë¸ ë‚´ë¶€ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] ë¸Œëœë“œ ë§¨ ì•(ë¯¸ì…ë ¥ ì‹œ ìƒëµ)
- [ ] ì¬ë£Œ,ìˆ˜ëŸ‰ ìƒí’ˆëª… ë§¨ ë’¤(ë¯¸ì…ë ¥ ì‹œ ìƒëµ)
- [ ] í•µì‹¬í‚¤ì›Œë“œ ë¸”ë¡ ì—°ì†Â·ì´ˆë°˜ ë°°ì¹˜
- [ ] ë™ì¼ í† í° â‰¤ 2íšŒ(ë³µí•©ì–´ ì ‘ë‘ í¬í•¨)
- [ ] ì—°ì† ë¸”ë¡ â‰¥ 2 ì„±ë¦½(í•µì‹¬ + ë³´ì¡°)
- [ ] ê¸¸ì´: ìì—°=í‰ê·  Â± í•œ ë‹¨ì–´ / ê´‘ê³ =í‰ê·  +1~+3 ë‹¨ì–´
- [ ] ì¬ë£Œ(í˜•íƒœ)â†’ìˆ˜ëŸ‰(ë¬´ê²Œ) ìˆœìœ¼ë¡œ ë§¨ ë ë°°ì¹˜
- [ ] ì™¸ë¶€ ë‹¨ì–´ ë¯¸ì‚¬ìš©({selected_keywords} + ì…ë ¥í‚¤ì›Œë“œë§Œ)"""


def generate_product_name_prompt(selected_keywords: list, core_keyword_data: KeywordBasicData, brand: str = None, material: str = None, quantity: str = None, length_stats: str = None) -> str:
    """Step 4 ìƒí’ˆëª… ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    from src.toolbox.formatters import format_int
    
    # ì„ íƒëœ í‚¤ì›Œë“œë“¤ì„ ìƒì„¸ ì •ë³´ì™€ í•¨ê»˜ í¬ë§·
    if selected_keywords and len(selected_keywords) > 0 and hasattr(selected_keywords[0], 'keyword'):
        # KeywordBasicData ê°ì²´ë“¤ì¸ ê²½ìš°
        keywords_str = ""
        for i, kw_data in enumerate(selected_keywords, 1):
            keywords_str += f"\n   {i}. {kw_data.keyword} (ì›”ê²€ìƒ‰ëŸ‰: {format_int(kw_data.search_volume)}, ì „ì²´ìƒí’ˆìˆ˜: {format_int(kw_data.total_products)})"
    else:
        # ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° (ê¸°ì¡´ ë°©ì‹)
        keywords_str = ", ".join(selected_keywords) if selected_keywords else "í‚¤ì›Œë“œ ì—†ìŒ"
    
    # í•µì‹¬ í‚¤ì›Œë“œ ì •ë³´
    if hasattr(core_keyword_data, 'keyword'):
        core_keyword_str = f"{core_keyword_data.keyword} (ì›”ê²€ìƒ‰ëŸ‰: {format_int(core_keyword_data.search_volume)}, ì „ì²´ìƒí’ˆìˆ˜: {format_int(core_keyword_data.total_products)})"
    else:
        core_keyword_str = str(core_keyword_data)
    
    # ë¸Œëœë“œëª…, ì¬ë£Œ, ìˆ˜ëŸ‰ ì •ë³´ ì²˜ë¦¬ (ì—†ëŠ” ê²½ìš° ëª…í™•íˆ í‘œì‹œ)
    brand_info = f"ë¸Œëœë“œëª…: {brand}" if brand else "ë¸Œëœë“œëª…: ì§€ì •ë˜ì§€ ì•ŠìŒ (ìƒëµ)"
    material_info = f"ì¬ë£Œ(í˜•íƒœ): {material}" if material else "ì¬ë£Œ(í˜•íƒœ): ì§€ì •ë˜ì§€ ì•ŠìŒ (ìƒëµ)"
    quantity_info = f"ìˆ˜ëŸ‰(ë¬´ê²Œ): {quantity}" if quantity else "ìˆ˜ëŸ‰(ë¬´ê²Œ): ì§€ì •ë˜ì§€ ì•ŠìŒ (ìƒëµ)"
    
    return DEFAULT_PRODUCT_NAME_GENERATION_PROMPT.format(
        selected_keywords=keywords_str,
        core_keyword=core_keyword_str,
        brand=brand_info,
        material=material_info, 
        quantity=quantity_info,
        length_stats=length_stats or "í†µê³„ ì •ë³´ ì—†ìŒ"
    )